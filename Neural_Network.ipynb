{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "d90d2413-ec64-4820-b0e9-d78ecd83e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "      \n",
    "#Hier onder staan alle activatie functies en hun afgeleide\n",
    "def Sigmoid(i):\n",
    "    return 1/(1 + np.exp(-i))\n",
    "\n",
    "def ReLu(i):\n",
    "    return i * (i > 0)\n",
    "\n",
    "def AfgeleideSigmoid(i):\n",
    "    return Sigmoid(i) * (1- Sigmoid(i))\n",
    "\n",
    "def AfgeleideReLu(i):\n",
    "    return 1 * (i > 0)\n",
    "\n",
    "def Softmax(i):\n",
    "    return np.exp(i) / np.sum(np.exp(i), axis=0)\n",
    "\n",
    "def AfgeleideSoftmax(i):\n",
    "    return (Softmax(i) * np.identity(Softmax(i).size) - Softmax(i).transpose() @ Softmax(i))\n",
    "\n",
    "def convert(x, is_y = False):\n",
    "    if isinstance(x, pd.DataFrame) or isinstance(x, pd.Series):\n",
    "        x = x.to_numpy()\n",
    "    \n",
    "    ls = []\n",
    "    i = 0\n",
    "    \n",
    "    for row in x:\n",
    "        if not is_y:\n",
    "            if not isinstance(row[0], np.ndarray):\n",
    "                ls.append(np.array([row]))\n",
    "            else:\n",
    "                ls.append(row)\n",
    "        else:\n",
    "            if not isinstance(x[i], np.ndarray):\n",
    "                ls.append(np.array([x[i]]))\n",
    "            else:\n",
    "                ls.append(x[i]) \n",
    "        i += 1\n",
    "    \n",
    "    ls \n",
    "    \n",
    "    return np.array(ls)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "be862b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "\n",
    "#Functie om een laag te initialiseren\n",
    "def Init_layer(layertype, neurons, previous_layer = False, function = False):\n",
    "    if layertype == \"input\": \n",
    "        return{\n",
    "        \"output\": np.zeros(neurons)\n",
    "    }\n",
    "    elif layertype == \"hidden\":\n",
    "        return{\n",
    "        \"weights\": np.random.normal(0, 1, size=(previous_layer[\"output\"].size, neurons)),\n",
    "        \"bias\": np.random.normal(0, 1, neurons),\n",
    "        \"function\": function,\n",
    "        \"output\": np.zeros(neurons) \n",
    "    }\n",
    "    elif layertype == \"output\":\n",
    "        return{\n",
    "        \"weights\": np.random.normal(0, 1, size=(previous_layer[\"output\"].size, neurons)),\n",
    "        \"bias\": np.random.normal(0, 1, neurons),\n",
    "        \"function\": function,\n",
    "        \"output\": np.zeros(neurons)       \n",
    "    }\n",
    "        \n",
    "def Add_layer(layertype, neurons, function = False):\n",
    "    #Als de nieuwe layer de eerste laag is heeft het geen previous_layer en function nodig\n",
    "    if len(layers) == 0:\n",
    "        layers.append(Init_layer(layertype, neurons))\n",
    "    else:\n",
    "        previous_layer = layers[len(layers) - 1]\n",
    "        layers.append(Init_layer(layertype, neurons, previous_layer, function))\n",
    "        \n",
    "#zelfde seed voor debugging\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "a9642ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feedforward(layer, previous_layer):\n",
    "    #Eerst moeten we de dotproduct van de input en de weights berekenen\n",
    "    neuronvalues = np.dot(previous_layer[\"output\"], layer[\"weights\"])\n",
    "    \n",
    "    #vervolgens tellen we de bias op bij het dotproduct\n",
    "    neuronvalues = neuronvalues + layer[\"bias\"]\n",
    "    \n",
    "    #vervolgens passen we de activatie functie toe op de opsomming\n",
    "    if layer[\"function\"] == \"relu\":\n",
    "        neuronvalues = ReLu(neuronvalues)\n",
    "    elif layer[\"function\"] == \"softmax\":\n",
    "        neuronvalues = Softmax(neuronvalues)\n",
    "    elif layer[\"function\"] == \"sigmoid\":\n",
    "        neuronvalues = Sigmoid(neuronvalues)\n",
    "    \n",
    "    #print(\"neuronvalues\", neuronvalues)   \n",
    "    #zet de output van de laag op de neuronvalues\n",
    "    layer[\"output\"] = neuronvalues\n",
    "\n",
    "\n",
    "def BackPropagate(output_error, current_layer, previous_layer):\n",
    "    \n",
    "    #check the function used\n",
    "    function = current_layer[\"function\"]\n",
    "    \n",
    "    #afgeleide error berekenen\n",
    "    if function == \"sigmoid\":\n",
    "        input_error = np.dot(AfgeleideSigmoid(current_layer[\"output\"]) * output_error, current_layer[\"weights\"].T)\n",
    "    elif function == \"relu\":\n",
    "        input_error = np.dot(AfgeleideReLu(current_layer[\"output\"]) * output_error, current_layer[\"weights\"].T)\n",
    "    elif function == \"softmax\":\n",
    "        input_error = np.dot(AfgeleideSoftmax(current_layer[\"output\"]) * output_error, current_layer[\"weights\"].T)\n",
    "    #print(\"error\", input_error)\n",
    "    \n",
    "    \n",
    "    #print(\"input\", previous_layer[\"output\"].T) \n",
    "    #print(\"output error\", output_error) \n",
    "    #bereken de error van deze laag\n",
    "    #print(previous_layer[\"output\"].T.shape)\n",
    "    #print(output_error.shape)\n",
    "    weights_error = np.dot(previous_layer[\"output\"].T, output_error)\n",
    "    #print(\"weights error\", weights_error)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #update weights en biases\n",
    "    #print(\"weights\", current_layer[\"weights\"])\n",
    "    current_layer[\"weights\"] -= learning_rate * weights_error\n",
    "    #print(\"Updated weights\", current_layer[\"weights\"])\n",
    "    \n",
    "    #print(\"bias\", current_layer[\"bias\"])\n",
    "    current_layer[\"bias\"] -= learning_rate * output_error\n",
    "    #print(\"Updated bias\", current_layer[\"bias\"])\n",
    "    \n",
    "    return input_error\n",
    "   \n",
    "   \n",
    "def TrainNetwork(index, X, y):\n",
    "     \n",
    "    #Insert the input\n",
    "    layers[0][\"output\"] = X[index]\n",
    "    \n",
    "    #loop through the layers for feedforwarding\n",
    "    layers_to_loop = len(layers) - 1\n",
    "\n",
    "    for i in range(layers_to_loop):\n",
    "        Feedforward(layers[i + 1], layers[i])\n",
    "\n",
    "    #print actual output\n",
    "    actual_output = y[index]\n",
    "    #print(\"Actual error\", actual_output)\n",
    "    \n",
    "    #layers    \n",
    "    output_layer = layers[len(layers)-1]\n",
    "\n",
    "    error = 2*(output_layer[\"output\"] - y[index])/y.size \n",
    "    \n",
    "    for i in reversed(range(1, len(layers))):\n",
    "        error = BackPropagate(error, layers[i], layers[i - 1])  \n",
    "        \n",
    "\n",
    "\n",
    "def TrainWithOneDataset(X, y):\n",
    "    for i in range(len(y)):\n",
    "        #print(\"index\", i)        \n",
    "        TrainNetwork(i, X, y)\n",
    "\n",
    "\n",
    "def Test(X, y, epoch):\n",
    "    y_pred = []\n",
    "    \n",
    "    for index in range(len(y)):\n",
    "        #Insert the input\n",
    "        layers[0][\"output\"] = X[index]\n",
    "        #print(\"Input:\", layers[0][\"output\"])\n",
    "        \n",
    "        #loop through the layers for feedforwarding\n",
    "        layers_to_loop = len(layers) - 1\n",
    "        for i in range(layers_to_loop):\n",
    "            Feedforward(layers[i + 1], layers[i])\n",
    "            \n",
    "        y_pred.append(RoundToBinary(layers[len(layers) - 1][\"output\"]))\n",
    "        \n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(\"Epoch:\", epoch, \"Accuracy\", accuracy)\n",
    "        \n",
    "def RoundToBinary(number):\n",
    "    if number >= 0.5:\n",
    "        return True\n",
    "    else:\n",
    "        return False       \n",
    "\n",
    "def TrainTest(X, y):\n",
    "    #reshape de biases zodat we matrix berekeningen kunnen toepassen\n",
    "    for i in range(1, len(layers)):  \n",
    "        layers[i][\"bias\"].shape = (1, len(layers[i][\"bias\"])) \n",
    "    \n",
    "    for i in range(epochs):\n",
    "        TrainWithOneDataset(X, y)\n",
    "        Test(X, y, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "e76f1178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy 0.5\n",
      "Epoch: 1 Accuracy 0.75\n",
      "Epoch: 2 Accuracy 1.0\n",
      "Epoch: 3 Accuracy 1.0\n",
      "Epoch: 4 Accuracy 1.0\n",
      "Epoch: 5 Accuracy 1.0\n",
      "Epoch: 6 Accuracy 1.0\n",
      "Epoch: 7 Accuracy 1.0\n",
      "Epoch: 8 Accuracy 0.75\n",
      "Epoch: 9 Accuracy 0.75\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.3\n",
    "epochs = 10\n",
    "\n",
    "Add_layer(\"input\", 2)\n",
    "Add_layer(\"hidden\", 3, \"relu\")\n",
    "Add_layer(\"output\", 1, \"sigmoid\")\n",
    "\n",
    "X_train = np.array([[[0,0]], [[0,1]], [[1,0]], [[1,1]]])\n",
    "y_train = np.array([[False], [True], [True], [False]])\n",
    "TrainTest(X_train, y_train)\n",
    "\n",
    "#in de derde epoch is er al een accuracy van 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "d2f87b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy 0.5\n",
      "Epoch: 1 Accuracy 0.5\n",
      "Epoch: 2 Accuracy 0.55\n",
      "Epoch: 3 Accuracy 0.61\n",
      "Epoch: 4 Accuracy 0.75\n",
      "Epoch: 5 Accuracy 0.83\n",
      "Epoch: 6 Accuracy 0.89\n",
      "Epoch: 7 Accuracy 0.96\n",
      "Epoch: 8 Accuracy 0.97\n",
      "Epoch: 9 Accuracy 0.98\n",
      "Epoch: 10 Accuracy 0.99\n",
      "Epoch: 11 Accuracy 0.99\n",
      "Epoch: 12 Accuracy 0.99\n",
      "Epoch: 13 Accuracy 0.99\n",
      "Epoch: 14 Accuracy 0.99\n",
      "Epoch: 15 Accuracy 0.99\n",
      "Epoch: 16 Accuracy 0.99\n",
      "Epoch: 17 Accuracy 0.99\n",
      "Epoch: 18 Accuracy 0.99\n",
      "Epoch: 19 Accuracy 0.99\n",
      "Epoch: 20 Accuracy 0.99\n",
      "Epoch: 21 Accuracy 1.0\n",
      "Epoch: 22 Accuracy 1.0\n",
      "Epoch: 23 Accuracy 1.0\n",
      "Epoch: 24 Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "#voor deze opdracht wil ik de iris dataset gebruiken die we ook bij de bootcamp hebben gebruikt\n",
    "#om het op het begin wat makkelijker te maken wil ik maar 2 soorten bloemen gebruiken\n",
    "from operator import truediv\n",
    "import seaborn as sns\n",
    "\n",
    "iris = sns.load_dataset('iris')\n",
    "\n",
    "#Ik drop voor nu alle rows voor virginica zodat we een makkelijkere output hebben\n",
    "iris = iris.loc[iris[\"species\"] != \"virginica\"]\n",
    "\n",
    "#Split de dataset in input en output\n",
    "y_train = iris[\"species\"]\n",
    "X_train = iris[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]]\n",
    "\n",
    "#Verander de output voor binaire waardes\n",
    "y_train.replace(\"setosa\", 0, inplace = True)\n",
    "y_train.replace(\"versicolor\", 1, inplace = True)\n",
    "\n",
    "#leeg de layers list\n",
    "layers = []\n",
    "\n",
    "learning_rate = 1\n",
    "epochs = 25\n",
    "\n",
    "Add_layer(\"input\", 4)\n",
    "Add_layer(\"hidden\", 6, \"relu\")\n",
    "Add_layer(\"output\", 1, \"sigmoid\")\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "#we moeten de dataset omzetten naar een dataset die we hier voor kunnen gebruiken\n",
    "X_train = convert(X_train)\n",
    "\n",
    "TrainTest(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "12353d9ca1c9f5dd1ea0559f293f259ead9fdf0978f7cf0f86dddd3358f761e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
